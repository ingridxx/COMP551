{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randrange\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['ID', 'Clump_Thickness', 'Uniformity_of_Cell_Size', 'Uniformity_of_Cell_Shape',\n",
    "                       'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin',\n",
    "                       'Normal_Nucleoli', 'Mitoses', 'Class']\n",
    "bc_df = pd.read_csv(\"../Downloads/breast-cancer-wisconsin.data\", names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0\n",
       "Clump_Thickness                0\n",
       "Uniformity_of_Cell_Size        0\n",
       "Uniformity_of_Cell_Shape       0\n",
       "Marginal_Adhesion              0\n",
       "Single_Epithelial_Cell_Size    0\n",
       "Bare_Nuclei                    0\n",
       "Bland_Chromatin                0\n",
       "Normal_Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bare_Nuclei: 16 missing\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(bc_df.columns,(bc_df.values.astype(str) == '?').sum(axis = 0)):\n",
    "    if j > 0:\n",
    "        print(str(i) + ': ' + str(j) + ' missing')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the 16 samples with missing bare nuclei information.\n",
    "bc_df = bc_df[bc_df.Bare_Nuclei!='?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_df=bc_df.astype(float)\n",
    "bc_df['Class']=bc_df['Class'].map({2:0, 4:1})\n",
    "#Dropping the irrelevant ID column \n",
    "bc_df=bc_df.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_df.shape #683x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clump_Thickness  Uniformity_of_Cell_Size  Uniformity_of_Cell_Shape  \\\n",
       "694              3.0                      1.0                       1.0   \n",
       "695              2.0                      1.0                       1.0   \n",
       "696              5.0                     10.0                      10.0   \n",
       "697              4.0                      8.0                       6.0   \n",
       "698              4.0                      8.0                       8.0   \n",
       "\n",
       "     Marginal_Adhesion  Single_Epithelial_Cell_Size  Bare_Nuclei  \\\n",
       "694                1.0                          3.0          2.0   \n",
       "695                1.0                          2.0          1.0   \n",
       "696                3.0                          7.0          3.0   \n",
       "697                4.0                          3.0          4.0   \n",
       "698                5.0                          4.0          5.0   \n",
       "\n",
       "     Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
       "694              1.0              1.0      1.0      0  \n",
       "695              1.0              1.0      1.0      0  \n",
       "696              8.0             10.0      2.0      1  \n",
       "697             10.0              6.0      1.0      1  \n",
       "698             10.0              4.0      1.0      1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class 2 = benign, class 4 = malignant\n",
    "bc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, percentage=0.5, lr=0.01, max_iter=10000, beta=0.99, reg_term=0):  # percentage = train/cv+test split\n",
    "#        self.data = data\n",
    "        self.percentage = percentage\n",
    "        self.gradient_values, self.train_acc_values, self.cv_acc_values = [], [], []\n",
    "        self.cv_acc, self.select_line, self.cv_acc_mean = 0, 0, 0\n",
    "        self.learning_rate = lr\n",
    "        self.max_iter = max_iter\n",
    "        self.beta = beta\n",
    "        self.reg_term = reg_term\n",
    "        \n",
    "    def predict_proba(self, X, theta):\n",
    "        return self.sigmoid(np.dot(X, theta))\n",
    "\n",
    "    def predict(self, X, theta):\n",
    "        prediction = self.predict_proba(X, theta)\n",
    "        predict_arr = []\n",
    "        for i in prediction:\n",
    "            if i>=0.5:\n",
    "                predict_arr.append(1)\n",
    "            else:\n",
    "                predict_arr.append(0)\n",
    "\n",
    "        return predict_arr\n",
    "\n",
    "    def accuracy(self, predict_arr, y):\n",
    "        correct = 0\n",
    "        for i,j in zip(predict_arr, y):\n",
    "            if i==j[0]:\n",
    "                correct+=1\n",
    "        return correct/len(y)  # accuracy = # tp+tn / total\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def gradient(self, X, y, theta, lambdaa):  # lambdaa is regularization term\n",
    "        N, D = len(X[0]), len(X[0])\n",
    "        yh = self.sigmoid(np.dot(X, theta))\n",
    "        grad = np.dot(X.T, yh-y) / N\n",
    "        grad[1:] += lambdaa * theta[1:]\n",
    "        return grad\n",
    "    \n",
    "    def fit(self, X, y, cv_X, cv_y, learning_rate=0.1, max_iter=10000, beta=0.99, reg_term=0.5):  # attempted termination condition - lack of improvement in cross validation set\n",
    "        learning_rate = self.learning_rate\n",
    "        max_iter = self.max_iter\n",
    "        beta = self.beta\n",
    "        reg_term = self.reg_term\n",
    "        N, D = len(X[0]), len(X[0])\n",
    "        theta = np.zeros((len(X[0]), 1))\n",
    "        y = np.reshape(y, (-1,1))  # creates two-dimensional array\n",
    "        cv_y = np.reshape(cv_y, (-1,1))\n",
    "        iterate, cv_acc, prev_cv_acc, d_theta = 0, 0, 0, 0\n",
    "        max_cv_acc = 0  # maximum cross validation accuracy - records thetas at highest cv_acc \n",
    "        best_theta = theta\n",
    "        g = np.inf\n",
    "        eps = 1e-2\n",
    "        while (np.linalg.norm(g) > eps):  # can add in 'or cv_acc>=prev_cv_acc-0.03' to stop when gradient becomes too small, 0.03 gives buffer\n",
    "            g = self.gradient(X, y, theta, reg_term)\n",
    "            d_theta = (1-beta)*g + beta*d_theta  # momentum\n",
    "            theta = theta-learning_rate*d_theta\n",
    "            \n",
    "            if iterate % 10 == 0:\n",
    "                cv_pred = self.predict(cv_X, theta)\n",
    "                prev_cv_acc = cv_acc\n",
    "                cv_acc = self.accuracy(cv_pred, cv_y)\n",
    "                train_pred = self.predict(X, theta)\n",
    "                train_acc = self.accuracy(train_pred, y)\n",
    "            if cv_acc >= max_cv_acc:  # checks if maximum accuracy thus far\n",
    "                max_cv_acc = cv_acc\n",
    "                best_theta = theta\n",
    "                self.select_line = iterate\n",
    "            iterate+=1\n",
    "            self.gradient_values.append(np.linalg.norm(g))\n",
    "            self.train_acc_values.append(train_acc)\n",
    "            self.cv_acc_values.append(cv_acc)\n",
    "#             if iterate % 100 == 0:\n",
    "#                 print(np.linalg.norm(g)/len(X))\n",
    "            if iterate > max_iter:  # since it may not always converge, place a hard ceiling on number of iterations\n",
    "                break\n",
    "        print(max_cv_acc)\n",
    "        print(cv_acc)\n",
    "        self.cv_acc = max_cv_acc\n",
    "        self.cv_acc_mean = np.mean(self.cv_acc_values)\n",
    "        return best_theta\n",
    "    \n",
    "    def get_test_acc(self, test_X, test_y, thetas):\n",
    "        test_y = np.reshape(test_y, (-1,1))\n",
    "        \n",
    "        return self.accuracy(self.predict(test_X, thetas), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = bc_df\n",
    "new_input.insert(0, column='Bias', value=1)\n",
    "new_input = new_input.sample(frac=1)  # randomly shuffles dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9632352941176471\n",
      "0.9485294117647058\n",
      "0.9779411764705882\n",
      "0.9705882352941176\n",
      "0.9703703703703703\n",
      "0.9703703703703703\n",
      "0.9705882352941176\n",
      "0.9705882352941176\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9632352941176471\n",
      "0.9558823529411765\n",
      "0.9705882352941176\n",
      "0.9705882352941176\n",
      "0.9703703703703703\n",
      "0.9703703703703703\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9632352941176471\n",
      "0.9485294117647058\n",
      "0.9779411764705882\n",
      "0.9705882352941176\n",
      "0.9703703703703703\n",
      "0.9629629629629629\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9632352941176471\n",
      "0.9485294117647058\n",
      "0.9852941176470589\n",
      "0.9705882352941176\n",
      "0.9703703703703703\n",
      "0.9629629629629629\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9632352941176471\n",
      "0.9485294117647058\n",
      "0.9852941176470589\n",
      "0.9705882352941176\n",
      "0.9777777777777777\n",
      "0.9629629629629629\n",
      "0.9852941176470589\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9632352941176471\n",
      "0.9485294117647058\n",
      "0.9852941176470589\n",
      "0.9705882352941176\n",
      "0.9777777777777777\n",
      "0.9629629629629629\n",
      "0.9926470588235294\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n",
      "0.9779411764705882\n"
     ]
    }
   ],
   "source": [
    "folds = 5\n",
    "accuracies = []\n",
    "mean_acc = []\n",
    "learning_rate = [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "for lr in learning_rate:\n",
    "    for i in range(folds):\n",
    "\n",
    "        start_bias = 0\n",
    "        end_bias = 1\n",
    "        if i>0:\n",
    "            start_bias = 1  # to exclude last term in previous partition\n",
    "        if i >= folds-1:\n",
    "            end_bias = 0\n",
    "        percentage = 1/folds\n",
    "        length = len(new_input)\n",
    "        test_set = new_input.iloc[int(percentage*(i)*length+start_bias):int(percentage*(i+1)*length), :]\n",
    "\n",
    "        train_set_1 = new_input.iloc[int(percentage*(i+1)*length)+end_bias:length, :]\n",
    "        train_set_2 = new_input.iloc[0:int(percentage*(i)*length), :]\n",
    "        train_set = pd.concat([train_set_1, train_set_2])\n",
    "        \n",
    "        train_X = train_set.iloc[:, :-1]\n",
    "        train_y = train_set.iloc[:, -1]\n",
    "\n",
    "        test_X = test_set.iloc[:, :-1]\n",
    "        test_y = test_set.iloc[:, -1]\n",
    "        \n",
    "        log_reg = LogisticRegression(percentage=0.6, lr = lr)\n",
    "        log_reg.fit(train_X.values, train_y.values, test_X.values, test_y.values)\n",
    "        accuracies.append(log_reg.cv_acc_mean)\n",
    "        plt.figure()\n",
    "        plt.plot(log_reg.train_acc_values, label = 'Training accuracy')\n",
    "        plt.plot(log_reg.cv_acc_values, label='CV accuracy')\n",
    "        plt.axvline(log_reg.select_line, color='r', label='Weights Selected')\n",
    "        plt.plot([], [], ' ', label=\"Learning Rate: \"+str(log_reg.learning_rate))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "   print(\"Average Accuracy: \"+str(np.mean(accuracies)))\n",
    "    mean_acc.append(np.mean(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate, mean_acc, 'o')\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"log(Learning Rate)\")\n",
    "plt.ylabel(\"Mean Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
